{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this notebook to write your code for problem 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def load_data(filename, skiprows = 1):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string.\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=' ')\n",
    "\n",
    "# Load the training and test data\n",
    "data_train = load_data('data/training_data.txt', 1)\n",
    "X_train = data_train[:2000, 1:]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "y_train = data_train[:2000, 0]\n",
    "#y_train = keras.utils.np_utils.to_categorical(y_train_pre,num_classes=2)\n",
    "\n",
    "data_test = load_data('data/test_data.txt', 1)\n",
    "X_test = data_test[:,:]\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matt\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Matt\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Matt\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "xMean = np.mean(X_train,axis=0)\n",
    "xStd = np.std(X_train,axis=0)\n",
    "X_train = (X_train - xMean)/xStd\n",
    "X_test = (X_test - xMean)/xStd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.32412084, 1.41047368, 1.06807818, 0.70415836, 0.86363823,\n",
       "       0.98327972, 0.70336264, 0.68088178, 0.62601917, 0.55458002,\n",
       "       0.56249444, 0.52623569, 0.54074023, 0.54578292, 0.5249419 ,\n",
       "       0.64217132, 0.5234797 , 0.47782424, 0.48480512, 0.52657288,\n",
       "       0.46827236, 0.45562155, 0.47652807, 0.42      , 0.41724813,\n",
       "       0.41590263, 0.45999022, 0.4081066 , 0.35959839, 0.3957575 ,\n",
       "       0.41957598, 0.4286712 , 0.37158579, 0.36758128, 0.40137264,\n",
       "       0.50233057, 0.47490631, 0.38935845, 0.51295126, 0.3537174 ,\n",
       "       0.38898715, 0.39136173, 0.52969425, 0.31937439, 0.34044089,\n",
       "       0.31360963, 0.37087869, 0.3181179 , 0.38314358, 0.44485953,\n",
       "       0.37574459, 0.35954972, 0.35714283, 0.34449819, 0.37040383,\n",
       "       0.30643107, 0.32185556, 0.41519995, 0.28740912, 0.30018494,\n",
       "       0.2987909 , 0.31977492, 0.44312414, 0.36104155, 0.32972564,\n",
       "       0.30645717, 0.36367018, 0.27705415, 0.30156923, 0.32801067,\n",
       "       0.2987909 , 0.43089558, 0.29738695, 0.26502641, 0.27142402,\n",
       "       0.35263437, 0.32006093, 0.33822478, 0.29023956, 0.30317652,\n",
       "       0.30695928, 0.33451457, 0.277157  , 0.31587181, 0.28628482,\n",
       "       0.31532681, 0.31291532, 0.29985997, 0.27683208, 0.26366456,\n",
       "       0.30968371, 0.2264862 , 0.26861869, 0.25768197, 0.32523069,\n",
       "       0.28326489, 0.25155318, 0.28770645, 0.26951067, 0.32507076,\n",
       "       0.25984418, 0.28221269, 0.20629106, 0.28326489, 0.30557323,\n",
       "       0.27276363, 0.28035513, 0.23212927, 0.26814921, 0.29846943,\n",
       "       0.3170552 , 0.26320904, 0.26198473, 0.29559263, 0.3205854 ,\n",
       "       0.3508561 , 0.26029022, 0.2420723 , 0.29309384, 0.24616864,\n",
       "       0.19829019, 0.33475962, 0.23366429, 0.30838288, 0.36964307,\n",
       "       0.20813217, 0.30906148, 0.22616587, 0.26054558, 0.29051678,\n",
       "       0.24489794, 0.24533854, 0.22334726, 0.24228908, 0.34589594,\n",
       "       0.25980762, 0.4177607 , 0.26113407, 0.27799101, 0.29309384,\n",
       "       0.23515102, 0.22616587, 0.25275284, 0.22817537, 0.26320904,\n",
       "       0.22130296, 0.23366429, 0.19869323, 0.27579703, 0.25768197,\n",
       "       0.2277806 , 0.28354717, 0.20209899, 0.20366394, 0.2483868 ,\n",
       "       0.23323808, 0.32171416, 0.22817537, 0.2128826 , 0.1862901 ,\n",
       "       0.2059126 , 0.24576411, 0.26452788, 0.23830862, 0.21752931,\n",
       "       0.19708881, 0.23016299, 0.19635682, 0.26072016, 0.22536859,\n",
       "       0.23558438, 0.23251667, 0.27198346, 0.23446961, 0.18193405,\n",
       "       0.22517549, 0.22838345, 0.20209899, 0.19158288, 0.24533854,\n",
       "       0.20730654, 0.1891428 , 0.27924004, 0.17964131, 0.21962696,\n",
       "       0.24693116, 0.21534855, 0.20954952, 0.20851619, 0.21361414,\n",
       "       0.21789676, 0.21729243, 0.14668333, 0.19977738, 0.1977372 ,\n",
       "       0.23941387, 0.20058913, 0.2215852 , 0.20664946, 0.19635682,\n",
       "       0.19943671, 0.1841494 , 0.18765927, 0.17366347, 0.19977738,\n",
       "       0.18983941, 0.16844881, 0.31195993, 0.20730654, 0.15362291,\n",
       "       0.16240382, 0.18159295, 0.26211448, 0.17899441, 0.15362291,\n",
       "       0.17964131, 0.1786365 , 0.176     , 0.26502075, 0.21484646,\n",
       "       0.22207881, 0.1891428 , 0.18159295, 0.28962735, 0.19562975,\n",
       "       0.1901552 , 0.20327076, 0.2234077 , 0.18950198, 0.14745847,\n",
       "       0.21395093, 0.21312907, 0.17993054, 0.22413389, 0.21395093,\n",
       "       0.16497273, 0.17153425, 0.18159295, 0.18611556, 0.21361414,\n",
       "       0.20009748, 0.23473389, 0.25040767, 0.19291449, 0.19708881,\n",
       "       0.1879468 , 0.21945159, 0.16208331, 0.15304901, 0.19470747,\n",
       "       0.17092688, 0.17932931, 0.15612495, 0.19562975, 0.18734994,\n",
       "       0.16240382, 0.18765927, 0.21824527, 0.21176402, 0.14      ,\n",
       "       0.20532657, 0.18983941, 0.21395093, 0.13295112, 0.19869323,\n",
       "       0.16813982, 0.15019654, 0.19899749, 0.19943671, 0.17092688,\n",
       "       0.23218742, 0.17153425, 0.1499033 , 0.18225257, 0.1766805 ,\n",
       "       0.34473758, 0.22130522, 0.16560193, 0.17092688, 0.15304901,\n",
       "       0.18482154, 0.24091285, 0.24198347, 0.24448926, 0.1926136 ,\n",
       "       0.19534329, 0.18377976, 0.15944905, 0.16529973, 0.22517549,\n",
       "       0.14      , 0.16529973, 0.21312907, 0.16269911, 0.16813982,\n",
       "       0.22654801, 0.15019654, 0.15913516, 0.15944905, 0.17092688,\n",
       "       0.1977372 , 0.24388317, 0.16240382, 0.18701872, 0.16560193,\n",
       "       0.20352887, 0.18765927, 0.20039711, 0.16269911, 0.1879468 ,\n",
       "       0.18482154, 0.21945159, 0.17124252, 0.18225257, 0.25424201,\n",
       "       0.17964131, 0.20532657, 0.1974234 , 0.21777052, 0.1254751 ,\n",
       "       0.1901552 , 0.17726816, 0.14027117, 0.18983941, 0.15091388,\n",
       "       0.15973728, 0.19229145, 0.18225257, 0.23296137, 0.18734994,\n",
       "       0.16      , 0.16587947, 0.21236761, 0.13678816, 0.15696815,\n",
       "       0.1926136 , 0.21108292, 0.18225257, 0.1980303 , 0.16873352,\n",
       "       0.15671311, 0.16529973, 0.15944905, 0.18765927, 0.17153425,\n",
       "       0.16560193, 0.15944905, 0.23919866, 0.13295112, 0.24550153,\n",
       "       0.17932931, 0.16636105, 0.15387008, 0.17428425, 0.13320661,\n",
       "       0.15643209, 0.13652472, 0.19562975, 0.19097382, 0.22130522,\n",
       "       0.22465752, 0.13678816, 0.16560193, 0.18086183, 0.27113834,\n",
       "       0.12973434, 0.1254751 , 0.15671311, 0.1901552 , 0.14696938,\n",
       "       0.16873352, 0.13320661, 0.16321458, 0.113274  , 0.26329451,\n",
       "       0.15091388, 0.10430244, 0.113274  , 0.17092688, 0.12155246,\n",
       "       0.16      , 0.14696938, 0.16296932, 0.16240382, 0.14722771,\n",
       "       0.13295112, 0.15362291, 0.15671311, 0.21994317, 0.17092688,\n",
       "       0.14391317, 0.11749043, 0.14668333, 0.15671311, 0.13678816,\n",
       "       0.20814418, 0.12927103, 0.1436628 , 0.10888526, 0.12155246,\n",
       "       0.1436628 , 0.11348568, 0.15334927, 0.16899408, 0.13678816,\n",
       "       0.11348568, 0.13295112, 0.15719733, 0.12927103, 0.113274  ,\n",
       "       0.15304901, 0.14072669, 0.14051334, 0.14668333, 0.11348568,\n",
       "       0.16923061, 0.11771151, 0.13295112, 0.15046262, 0.14051334,\n",
       "       0.17398563, 0.12155246, 0.20352887, 0.15091388, 0.12155246,\n",
       "       0.13678816, 0.12178259, 0.14413535, 0.1436628 , 0.12178259,\n",
       "       0.17481133, 0.17726816, 0.18821265, 0.13678816, 0.18540496,\n",
       "       0.14391317, 0.07053368, 0.16240382, 0.13320661, 0.12155246,\n",
       "       0.15334927, 0.1436628 , 0.18282232, 0.15643209, 0.13295112,\n",
       "       0.12155246, 0.1436628 , 0.14027117, 0.11771151, 0.1436628 ,\n",
       "       0.12927103, 0.11749043, 0.14027117, 0.16899408, 0.24377038,\n",
       "       0.13678816, 0.14072669, 0.113274  , 0.13678816, 0.15362291,\n",
       "       0.14027117, 0.21994317, 0.12155246, 0.11749043, 0.09949874,\n",
       "       0.12155246, 0.13678816, 0.1436628 , 0.13295112, 0.12927103,\n",
       "       0.19614026, 0.14696938, 0.15334927, 0.19656805, 0.14745847,\n",
       "       0.12927103, 0.1260952 , 0.15362291, 0.15070169, 0.16321458,\n",
       "       0.14027117, 0.13652472, 0.16296932, 0.11771151, 0.14696938,\n",
       "       0.13320661, 0.22812058, 0.11348568, 0.113274  , 0.12214336,\n",
       "       0.14696938, 0.14      , 0.113274  , 0.11749043, 0.21777052,\n",
       "       0.16      , 0.10430244, 0.14722771, 0.11749043, 0.12155246,\n",
       "       0.09949874, 0.12927103, 0.18821265, 0.1254751 , 0.14      ,\n",
       "       0.12951834, 0.10430244, 0.14391317, 0.15019654, 0.16079801,\n",
       "       0.12927103, 0.113274  , 0.10449402, 0.19443251, 0.13722609,\n",
       "       0.10449402, 0.22036107, 0.08908423, 0.09444046, 0.15019654,\n",
       "       0.20838426, 0.19935897, 0.13678816, 0.17180221, 0.14722771,\n",
       "       0.113274  , 0.14722771, 0.15409088, 0.10449402, 0.12973434,\n",
       "       0.13722609, 0.12155246, 0.13320661, 0.17246449, 0.113274  ,\n",
       "       0.14027117, 0.113274  , 0.14051334, 0.15387008, 0.11348568,\n",
       "       0.1370219 , 0.12571396, 0.08924125, 0.10430244, 0.21334479,\n",
       "       0.12571396, 0.11366178, 0.113274  , 0.09967949, 0.2175408 ,\n",
       "       0.1370219 , 0.12951834, 0.1370219 , 0.11771151, 0.17572422,\n",
       "       0.12214336, 0.15362291, 0.19656805, 0.12991921, 0.10449402,\n",
       "       0.14051334, 0.15459625, 0.14072669, 0.10449402, 0.12214336,\n",
       "       0.12951834, 0.12178259, 0.15070169, 0.12571396, 0.13678816,\n",
       "       0.14696938, 0.12592061, 0.11366178, 0.12178259, 0.19614026,\n",
       "       0.18921945, 0.15046262, 0.11789826, 0.09444046, 0.09949874,\n",
       "       0.10430244, 0.10888526, 0.20414701, 0.10449402, 0.10908712,\n",
       "       0.14391317, 0.23610167, 0.14722771, 0.10430244, 0.12178259,\n",
       "       0.10888526, 0.12951834, 0.10430244, 0.17752746, 0.10888526,\n",
       "       0.1983028 , 0.14391317, 0.27669297, 0.12155246, 0.09949874,\n",
       "       0.10449402, 0.12227428, 0.15387008, 0.07053368, 0.12592061,\n",
       "       0.14391317, 0.12973434, 0.15445388, 0.10888526, 0.07053368,\n",
       "       0.15125806, 0.12973434, 0.09444046, 0.09444046, 0.14391317,\n",
       "       0.10888526, 0.10449402, 0.14722771, 0.08908423, 0.1254751 ,\n",
       "       0.15696815, 0.09444046, 0.07064701, 0.20206682, 0.15091388,\n",
       "       0.13678816, 0.11348568, 0.12973434, 0.08908423, 0.14432948,\n",
       "       0.1254751 , 0.11348568, 0.10888526, 0.08908423, 0.08337266,\n",
       "       0.15091388, 0.15409088, 0.15091388, 0.20176967, 0.15125806,\n",
       "       0.1370219 , 0.12571396, 0.10888526, 0.08908423, 0.11789826,\n",
       "       0.113274  , 0.10430244, 0.15387008, 0.08337266, 0.05469004,\n",
       "       0.12951834, 0.10908712, 0.14051334, 0.113274  , 0.10430244,\n",
       "       0.12973434, 0.11749043, 0.14072669, 0.10908712, 0.15091388,\n",
       "       0.10430244, 0.07722694, 0.10430244, 0.09444046, 0.10449402,\n",
       "       0.10888526, 0.14391317, 0.12571396, 0.11348568, 0.10430244,\n",
       "       0.10430244, 0.11348568, 0.09460972, 0.13379088, 0.12178259,\n",
       "       0.09460972, 0.10449402, 0.22715633, 0.08337266, 0.11348568,\n",
       "       0.11348568, 0.14413535, 0.10430244, 0.09444046, 0.12951834,\n",
       "       0.09949874, 0.07053368, 0.08908423, 0.04467662, 0.17246449,\n",
       "       0.12155246, 0.21173332, 0.08337266, 0.08337266, 0.1260952 ,\n",
       "       0.09967949, 0.12571396, 0.10430244, 0.19443251, 0.13722609,\n",
       "       0.12571396, 0.14106736, 0.1370219 , 0.10938007, 0.10888526,\n",
       "       0.11348568, 0.10908712, 0.09967949, 0.11348568, 0.12571396,\n",
       "       0.09444046, 0.1370219 , 0.18590051, 0.08337266, 0.17860571,\n",
       "       0.07053368, 0.113274  , 0.07053368, 0.113274  , 0.09460972,\n",
       "       0.09444046, 0.14413535, 0.11348568, 0.12571396, 0.10888526,\n",
       "       0.11771151, 0.12973434, 0.11348568, 0.23151674, 0.10464703,\n",
       "       0.10888526, 0.109252  , 0.14091132, 0.09444046, 0.113274  ,\n",
       "       0.11771151, 0.07053368, 0.11771151, 0.08908423, 0.13402985,\n",
       "       0.11789826, 0.07722694, 0.13343163, 0.07722694, 0.11366178,\n",
       "       0.17005587, 0.10430244, 0.10908712, 0.19141317, 0.06311894,\n",
       "       0.07735632, 0.10908712, 0.113274  , 0.34      , 0.08908423,\n",
       "       0.07053368, 0.15091388, 0.11771151, 0.10888526, 0.13343163,\n",
       "       0.10449402, 0.12571396, 0.11771151, 0.12155246, 0.10449402,\n",
       "       0.08337266, 0.10888526, 0.08337266, 0.09444046, 0.13379088,\n",
       "       0.09949874, 0.08908423, 0.08337266, 0.10908712, 0.16363068,\n",
       "       0.17005587, 0.08908423, 0.07722694, 0.10449402, 0.14745847,\n",
       "       0.08908423, 0.09444046, 0.13343163, 0.09444046, 0.        ,\n",
       "       0.09444046, 0.11789826, 0.09967949, 0.10430244, 0.10430244,\n",
       "       0.10449402, 0.11771151, 0.08337266, 0.10908712, 0.15070169,\n",
       "       0.08908423, 0.14745847, 0.09967949, 0.12991921, 0.12214336,\n",
       "       0.18906084, 0.09460972, 0.16674531, 0.12951834, 0.09444046,\n",
       "       0.09444046, 0.08337266, 0.09967949, 0.08337266, 0.06321392,\n",
       "       0.10888526, 0.08908423, 0.12623787, 0.06311894, 0.10449402,\n",
       "       0.113274  , 0.07722694, 0.11348568, 0.08337266, 0.12214336,\n",
       "       0.10449402, 0.05469004, 0.10449402, 0.06311894, 0.05469004,\n",
       "       0.08337266, 0.06311894, 0.08908423, 0.12571396, 0.07722694,\n",
       "       0.09949874, 0.07722694, 0.06311894, 0.05469004, 0.07722694,\n",
       "       0.08337266, 0.09967949, 0.07735632, 0.07722694, 0.08351647,\n",
       "       0.29125762, 0.11771151, 0.07053368, 0.07722694, 0.08924125,\n",
       "       0.14766178, 0.12197951, 0.12991921, 0.10908712, 0.07722694,\n",
       "       0.10449402, 0.07053368, 0.19717758, 0.07053368, 0.08908423,\n",
       "       0.10464703, 0.09444046, 0.13722609, 0.06311894, 0.12178259,\n",
       "       0.1370219 , 0.09949874, 0.12592061, 0.11380246, 0.06311894,\n",
       "       0.10449402, 0.09444046, 0.13402985, 0.08337266, 0.07053368,\n",
       "       0.07053368, 0.10908712, 0.07722694, 0.1665653 , 0.05469004,\n",
       "       0.12592061, 0.06311894, 0.09967949, 0.10449402, 0.07735632,\n",
       "       0.08924125, 0.06311894, 0.08337266, 0.08337266, 0.08337266,\n",
       "       0.08908423, 0.09444046, 0.08337266, 0.05469004, 0.08924125,\n",
       "       0.06311894, 0.08908423, 0.08908423, 0.09967949, 0.08908423,\n",
       "       0.09444046, 0.09444046, 0.08908423, 0.09444046, 0.06311894,\n",
       "       0.08337266, 0.15125806, 0.13343163, 0.07053368, 0.08337266,\n",
       "       0.10449402, 0.08908423, 0.07064701, 0.08924125, 0.14810807,\n",
       "       0.10430244, 0.08337266, 0.08337266, 0.11771151, 0.08924125,\n",
       "       0.11771151, 0.08924125, 0.09949874, 0.07053368, 0.06311894,\n",
       "       0.07053368, 0.06311894, 0.08337266, 0.12197951, 0.10888526,\n",
       "       0.10449402, 0.20707245, 0.10449402, 0.08351647, 0.09444046,\n",
       "       0.15445388, 0.07722694, 0.20707245, 0.08337266, 0.09444046,\n",
       "       0.03160696, 0.07735632, 0.08337266, 0.08337266, 0.07053368,\n",
       "       0.09460972, 0.06311894, 0.09460972, 0.10449402, 0.08908423,\n",
       "       0.11348568, 0.09981984, 0.07735632, 0.09460972, 0.08337266,\n",
       "       0.06311894, 0.07053368, 0.05469004, 0.10430244, 0.11771151,\n",
       "       0.08908423, 0.07722694, 0.09444046, 0.08337266, 0.08337266,\n",
       "       0.12214336, 0.08908423, 0.07722694, 0.08337266, 0.08908423,\n",
       "       0.06311894, 0.09460972, 0.05469004, 0.09444046, 0.08337266,\n",
       "       0.08908423, 0.09460972, 0.09460972, 0.09967949, 0.07722694,\n",
       "       0.04467662, 0.04467662, 0.08908423, 0.08908423, 0.14463402,\n",
       "       0.07722694, 0.10908712, 0.08337266, 0.08337266, 0.14810807,\n",
       "       0.12178259, 0.06311894, 0.08924125, 0.10449402, 0.08337266,\n",
       "       0.09967949, 0.06311894, 0.08337266, 0.07722694, 0.07053368,\n",
       "       0.09949874, 0.11805084, 0.09460972, 0.        , 0.10449402])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(X_train,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2C - Depth vs Width for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in problem 2, we have conveniently provided for your use code that loads, preprocesses, and deals with the uglies of the MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matt\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\Matt\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# load MNIST data into Keras format\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold 1 / 5\n",
      "Test accuracy: 0.6134663341645885\n",
      "Running Fold 2 / 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-da14a417f7aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mforest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianProcessClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mforest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\gaussian_process\\gpc.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    611\u001b[0m                                  % self.multi_class)\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 613\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\gaussian_process\\gpc.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;31m# Precompute quantities required for predictions which are independent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[1;31m# of actual query points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_sr_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m    756\u001b[0m                                        K2_gradient * K1[:, :, np.newaxis]))\n\u001b[0;32m    757\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m   1203\u001b[0m         \u001b[0mlength_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_length_scale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1205\u001b[1;33m             \u001b[0mdists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlength_scale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sqeuclidean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1206\u001b[0m             \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1207\u001b[0m             \u001b[1;31m# convert from upper-triangular matrix to square matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\spatial\\distance.py\u001b[0m in \u001b[0;36mpdist\u001b[1;34m(X, metric, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1712\u001b[0m             pdist_fn = getattr(_distance_wrap,\n\u001b[0;32m   1713\u001b[0m                                \"pdist_%s_%s_wrap\" % (metric_name, typ))\n\u001b[1;32m-> 1714\u001b[1;33m             \u001b[0mpdist_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1715\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(y_train, n_folds=n_folds, shuffle=True)\n",
    "\n",
    "pred = np.zeros(10000)\n",
    "\n",
    "for i, (train, test) in enumerate(skf):\n",
    "    print(\"Running Fold\", i+1, \"/\", n_folds)\n",
    "    forest = GaussianProcessClassifier()\n",
    "\n",
    "    forest = forest.fit(X_train[train], y_train[train]) \n",
    "    acc = forest.score(X_train[test],y_train[test])\n",
    "    \n",
    "    pred += forest.predict(X_test)\n",
    "    \n",
    "    print('Test accuracy:', acc)\n",
    "\n",
    "y_labs = np.maximum(0.,np.sign(pred-2.5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"labels.txt\",\"w\") \n",
    "file.write(\"Id,Prediction\\n\")\n",
    "for i,x in enumerate(y_labs):\n",
    "    file.write(\"%i,%i\\n\" % (i+1,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
